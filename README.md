# üè† Airbnb End-to-End Data Engineering Project

## üìã Overview

This project implements a complete end-to-end data engineering pipeline for Airbnb data using modern cloud technologies. The solution demonstrates best practices in data warehousing, transformation, and analytics using **Snowflake**, **dbt (Data Build Tool)**, and **AZURE**.

The pipeline processes Airbnb listings, bookings, and hosts data through a medallion architecture (Bronze ‚Üí Silver ‚Üí Gold), implementing incremental loading, slowly changing dimensions (SCD Type 2), and creating analytics-ready datasets.

## üèóÔ∏è Architecture

### Data Flow
```
Source Data (CSV) ‚Üí Azure ADLS ‚Üí Snowflake (Staging) ‚Üí Bronze Layer ‚Üí Silver Layer ‚Üí Gold Layer
                                                           ‚Üì              ‚Üì           ‚Üì
                                                      Raw Tables    Cleaned Data   Analytics
```

### Technology Stack

- **Cloud Data Warehouse**: Snowflake
- **Transformation Layer**: dbt (Data Build Tool)
- **Cloud Storage**: Azure ADLS (implied)
- **Version Control**: Git
- **Python**: 3.12+
- **Key dbt Features**:
  - Incremental models
  - Snapshots (SCD Type 2)
  - Custom macros
  - Jinja templating
  - Testing and documentation

## üìä Data Model

### Medallion Architecture

#### ü•â Bronze Layer (Raw Data)
Raw data ingested from staging with minimal transformations:
- `bronze_bookings` - Raw booking transactions
- `bronze_hosts` - Raw host information
- `bronze_listings` - Raw property listings

#### ü•à Silver Layer (Cleaned Data)
Cleaned and standardized data:
- `silver_bookings` - Validated booking records
- `silver_hosts` - Enhanced host profiles with quality metrics
- `silver_listings` - Standardized listing information with price categorization

#### ü•á Gold Layer (Analytics-Ready)
Business-ready datasets optimized for analytics:
- `obt` (One Big Table) - Denormalized fact table joining bookings, listings, and hosts
- `fact` - Fact table for dimensional modeling
- Ephemeral models for intermediate transformations

### Snapshots (SCD Type 2)
Slowly Changing Dimensions to track historical changes:
- `dim_bookings` - Historical booking changes
- `dim_hosts` - Historical host profile changes
- `dim_listings` - Historical listing changes

## üìÅ Project Structure

```
SnowflakeBnB/
‚îú‚îÄ‚îÄ README.md                           # This file
‚îú‚îÄ‚îÄ pyproject.toml                      # Python dependencies
‚îú‚îÄ‚îÄ main.py                             # Main execution script
‚îÇ
‚îú‚îÄ‚îÄ SourceData/                         # Raw CSV data files
‚îÇ   ‚îú‚îÄ‚îÄ bookings.csv
‚îÇ   ‚îú‚îÄ‚îÄ hosts.csv
‚îÇ   ‚îî‚îÄ‚îÄ listings.csv
‚îÇ
‚îú‚îÄ‚îÄ DDL/                                # Database schema definitions
‚îÇ   ‚îú‚îÄ‚îÄ ddl.sql                         # Table creation scripts
‚îÇ   ‚îî‚îÄ‚îÄ resources.sql
‚îÇ
‚îî‚îÄ‚îÄ AirBnb_Proj/                        # Main dbt project
    ‚îú‚îÄ‚îÄ dbt_project.yml                 # dbt project configuration
    ‚îú‚îÄ‚îÄ ExampleProfiles.yml             # Snowflake connection profile
    ‚îÇ
    ‚îú‚îÄ‚îÄ models/                         # dbt models
    ‚îÇ   ‚îú‚îÄ‚îÄ sources/
    ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ sources.yml             # Source definitions
    ‚îÇ   ‚îú‚îÄ‚îÄ bronze/                     # Raw data layer
    ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ bronze_bookings.sql
    ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ bronze_hosts.sql
    ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ bronze_listings.sql
    ‚îÇ   ‚îú‚îÄ‚îÄ silver/                     # Cleaned data layer
    ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ silver_bookings.sql
    ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ silver_hosts.sql
    ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ silver_listings.sql
    ‚îÇ   ‚îî‚îÄ‚îÄ gold/                       # Analytics layer
    ‚îÇ       ‚îú‚îÄ‚îÄ fact.sql
    ‚îÇ       ‚îú‚îÄ‚îÄ obt.sql
    ‚îÇ       ‚îî‚îÄ‚îÄ ephemeral/              # Temporary models
    ‚îÇ           ‚îú‚îÄ‚îÄ bookings.sql
    ‚îÇ           ‚îú‚îÄ‚îÄ hosts.sql
    ‚îÇ           ‚îî‚îÄ‚îÄ listings.sql
    ‚îÇ
    ‚îú‚îÄ‚îÄ macros/                         # Reusable SQL functions
    ‚îÇ   ‚îú‚îÄ‚îÄ generate_schema_name.sql    # Custom schema naming
    ‚îÇ   ‚îú‚îÄ‚îÄ multiply.sql                # Math operations
    ‚îÇ   ‚îú‚îÄ‚îÄ tag.sql                     # Categorization logic
    ‚îÇ   ‚îî‚îÄ‚îÄ trimmer.sql                 # String utilities
    ‚îÇ
    ‚îú‚îÄ‚îÄ analyses/                       # Ad-hoc analysis queries
    ‚îÇ   ‚îú‚îÄ‚îÄ explore.sql
    ‚îÇ   ‚îú‚îÄ‚îÄ if_else.sql
    ‚îÇ   ‚îî‚îÄ‚îÄ loop.sql
    ‚îÇ
    ‚îú‚îÄ‚îÄ snapshots/                      # SCD Type 2 configurations
    ‚îÇ   ‚îú‚îÄ‚îÄ dim_bookings.yml
    ‚îÇ   ‚îú‚îÄ‚îÄ dim_hosts.yml
    ‚îÇ   ‚îî‚îÄ‚îÄ dim_listings.yml
    ‚îÇ
    ‚îú‚îÄ‚îÄ tests/                          # Data quality tests
    ‚îÇ   ‚îî‚îÄ‚îÄ source_tests.sql
    ‚îÇ
    ‚îî‚îÄ‚îÄ seeds/                          # Static reference data


1. **Set Up Snowflake Database**
   
   Run the DDL scripts to create tables:
   ```bash
   # Execute DDL/ddl.sql in Snowflake to create staging tables
   ```

2. **Load Source Data**
   
   Load CSV files from `SourceData/` to Snowflake staging schema:
   - `bookings.csv` ‚Üí `AIRBNB.STAGING.BOOKINGS`
   - `hosts.csv` ‚Üí `AIRBNB.STAGING.HOSTS`
   - `listings.csv` ‚Üí `AIRBNB.STAGING.LISTINGS`

## üîß Usage

### Running dbt Commands

1. **Test Connection**
   ```bash
   cd AirBnb_Proj
   dbt debug
   ```

2. **Install Dependencies**
   ```bash
   dbt deps
   ```

3. **Run All Models**
   ```bash
   dbt run
   ```

4. **Run Specific Layer**
   ```bash
   dbt run --select bronze.*      # Run bronze models only
   dbt run --select silver.*      # Run silver models only
   dbt run --select gold.*        # Run gold models only
   ```

5. **Run Tests**
   ```bash
   dbt test
   ```

6. **Run Snapshots**
   ```bash
   dbt snapshot
   ```

7. **Generate Documentation**
   ```bash
   dbt docs generate
   dbt docs serve
   ```

8. **Build Everything**
   ```bash
   dbt build  # Runs models, tests, and snapshots
   ```

## üéØ Key Features

### 1. Incremental Loading
Bronze and silver models use incremental materialization to process only new/changed data:
```sql
{{ config(materialized='incremental') }}
{% if is_incremental() %}
    WHERE CREATED_AT > (SELECT COALESCE(MAX(CREATED_AT), '1900-01-01') FROM {{ this }})
{% endif %}
```

### 2. Custom Macros
Reusable business logic:
- **`tag()` macro**: Categorizes prices into 'low', 'medium', 'high'
  ```sql
  {{ tag('CAST(PRICE_PER_NIGHT AS INT)') }} AS PRICE_PER_NIGHT_TAG
  ```

### 3. Dynamic SQL Generation
The OBT (One Big Table) model uses Jinja loops for maintainable joins:
```sql
{% set configs = [...] %}
SELECT {% for config in configs %}...{% endfor %}
```

### 4. Slowly Changing Dimensions
Track historical changes with timestamp-based snapshots:
- Valid from/to dates automatically maintained
- Historical data preserved for point-in-time analysis

### 5. Schema Organization
Automatic schema separation by layer:
- Bronze models ‚Üí `AIRBNB.BRONZE.*`
- Silver models ‚Üí `AIRBNB.SILVER.*`
- Gold models ‚Üí `AIRBNB.GOLD.*`
  

## üêõ Troubleshooting

### Common Issues faced while working on project

1. **Connection Error**
   - Verify Snowflake credentials in `profiles.yml`
   - Check network connectivity
   - Ensure warehouse is running

2. **Compilation Error**
   - Run `dbt debug` to check configuration
   - Verify model dependencies
   - Check Jinja syntax

3. **Incremental Load Issues**
   - Run `dbt run --full-refresh` to rebuild from scratch
   - Verify source data timestamps


- [ ] Implement data masking for PII
- [ ] Add more comprehensive testing suite
